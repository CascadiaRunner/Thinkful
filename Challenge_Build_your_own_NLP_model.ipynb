{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Challenge - Build your own NLP model",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CascadiaRunner/Thinkful/blob/master/Challenge_Build_your_own_NLP_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "T5P7pIIcWQ0J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f0904635-c9f5-4b4f-fbe9-5414d2bc2ff4"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import sklearn\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from nltk.corpus import inaugural, stopwords\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('inaugural')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "Utln0I2NWS70",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bush = inaugural.raw('2001-Bush.txt')\n",
        "obama = inaugural.raw('2009-Obama.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdTeRpxjYSGW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def text_cleaner(text):\n",
        "    text = re.sub(r'\\n',' ',text)\n",
        "#     text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
        "#     text = ' '.join(text.split())\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_R5xva4PWZlV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bush = text_cleaner(bush)\n",
        "obama = text_cleaner(obama)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6NZPj_7XY5GJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en')\n",
        "bush_inaug = nlp(bush)\n",
        "obama_inaug = nlp(obama)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vc-vt-KaZk2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1819d620-49d5-4525-ad50-a1be7c17c53d"
      },
      "cell_type": "code",
      "source": [
        "# Group into sentences.\n",
        "bush_sents = [[sent, \"Bush\"] for sent in bush_inaug.sents]\n",
        "obama_sents = [[sent, \"Obama\"] for sent in obama_inaug.sents]\n",
        "\n",
        "# Combine the sentences from the two speeches.\n",
        "sentences = pd.DataFrame(bush_sents + obama_sents)\n",
        "sentences.columns = ['speech', 'president']\n",
        "sentences.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>speech</th>\n",
              "      <th>president</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(President, Clinton, ,, distinguished, guests,...</td>\n",
              "      <td>Bush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(With, a, simple, oath, ,, we, affirm, old, tr...</td>\n",
              "      <td>Bush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(As, I, begin, ,, I, thank, President, Clinton...</td>\n",
              "      <td>Bush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(And, I, thank, Vice, President, Gore, for, a,...</td>\n",
              "      <td>Bush</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(I, am, honored, and, humbled, to, stand, here...</td>\n",
              "      <td>Bush</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              speech president\n",
              "0  (President, Clinton, ,, distinguished, guests,...      Bush\n",
              "1  (With, a, simple, oath, ,, we, affirm, old, tr...      Bush\n",
              "2  (As, I, begin, ,, I, thank, President, Clinton...      Bush\n",
              "3  (And, I, thank, Vice, President, Gore, for, a,...      Bush\n",
              "4  (I, am, honored, and, humbled, to, stand, here...      Bush"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "bggoLZ3qcYwk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bag_of_words(text):\n",
        "    \n",
        "    # Filter out punctuation and stop words.\n",
        "    allwords = [token.lemma_\n",
        "                for token in text\n",
        "                if not token.is_punct\n",
        "                and not token.is_stop]\n",
        "    \n",
        "    # Return the most common words.\n",
        "    return [item[0] for item in Counter(allwords).most_common(100)]\n",
        "  \n",
        "def bow_features(sentences_df, common_words, verbose=False, batch_size=100):\n",
        "    word_counts = pd.DataFrame(columns=common_words)\n",
        "    i = 0\n",
        "    for sentence in sentences_df.iloc[:,0]:\n",
        "        # repeat this for every sentence\n",
        "        x = pd.Series(sentence).value_counts()\n",
        "        x = x[pd.Series([str(x) for x in x.index]).isin(common_words).values]\n",
        "        word_counts.loc[i,:] = 0\n",
        "        word_counts.loc[i,[str(x) for x in x.index]] = x.values\n",
        "        if verbose:\n",
        "            if i % batch_size == 0:\n",
        "                print(\"Processing row {}\".format(i))\n",
        "        i += 1\n",
        "    return word_counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_5YwUkucoSc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bushwords = bag_of_words(bush_inaug)\n",
        "obamawords = bag_of_words(obama_inaug)\n",
        "\n",
        "common_words = set(bushwords + obamawords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EFu1gRZsc3qp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7c873cbe-e4cf-4d6e-e47f-630fbc7594cf"
      },
      "cell_type": "code",
      "source": [
        "word_counts = bow_features(sentences, common_words, verbose=True)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing row 0\n",
            "Processing row 100\n",
            "Processing row 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nobj9FrQljZc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# create target variable\n",
        "# Here 0 indicates that Bush was the author\n",
        "# and if 1 then Obama is the author\n",
        "Y = (sentences.president == 'Obama').astype(int).values\n",
        "X = word_counts.astype(int).values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    Y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V3fdPTRddut3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7f181758-9b15-48f7-faf5-18961fd8d32f"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'n_estimators' : [50, 100, 200, 300],\n",
        "         'learning_rate' : [0.01, 0.05, 0.1, 0.20],\n",
        "         'max_depth' : [5, 10, 15, 20]}\n",
        "\n",
        "gbc = ensemble.GradientBoostingClassifier()\n",
        "clf = GridSearchCV(gbc, params, cv=5)\n",
        "\n",
        "train = clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print('Training set score:', clf.score(X_train, y_train))\n",
        "print('Test set score:', clf.score(X_test, y_test))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training set score: 0.9932432432432432\n",
            "Test set score: 0.640625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MRib0e4ldxwv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t3dg4VpYi4JQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "fb294329-37e8-4973-a650-7b97a568a965"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "bush=inaugural.paras('2001-Bush.txt')\n",
        "obama=inaugural.paras('2009-Obama.txt')\n",
        "bush_paras=[]\n",
        "obama_paras=[]\n",
        "for paragraph in bush:\n",
        "    para=paragraph[0]\n",
        "    #removing the double-dash from all words\n",
        "    para=[re.sub(r'--','',word) for word in para]\n",
        "    #Forming each paragraph into a string and adding it to the list of strings.\n",
        "    bush_paras.append(' '.join(para))\n",
        "    \n",
        "for paragraph in obama:\n",
        "    para=paragraph[0]\n",
        "    #removing the double-dash from all words\n",
        "    para=[re.sub(r'--','',word) for word in para]\n",
        "    #Forming each paragraph into a string and adding it to the list of strings.\n",
        "    obama_paras.append(' '.join(para))\n",
        "\n",
        "print(bush_paras[0:2])\n",
        "print(obama_paras[0:2])"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['President Clinton , distinguished guests and my fellow citizens , the peaceful transfer of authority is rare in history , yet common in our country .', 'As I begin , I thank President Clinton for his service to our nation .']\n",
            "['My fellow citizens :', 'I stand here today humbled by the task before us , grateful for the trust you have bestowed , mindful of the sacrifices borne by our ancestors .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yjarUQtpoVMo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQHTu-bBfp3s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91e3f2b9-365e-478a-8a08-f2c0d8d1a305"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "X_train, X_test = train_test_split(bush_paras, test_size=0.3, random_state=0)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
        "                             min_df=2, # only use words that appear at least twice\n",
        "                             stop_words='english', \n",
        "                             lowercase=True, #convert everything to lower case\n",
        "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
        "                             norm=None, #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
        "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
        "                            )\n",
        "\n",
        "#Applying the vectorizer\n",
        "bush_inaug_tfidf=vectorizer.fit_transform(bush_paras)\n",
        "print(\"Number of features: %d\" % bush_inaug_tfidf.get_shape()[1])\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yB8SXjUeiqa5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "961990f0-de3f-4a14-f364-4f921b607ec9"
      },
      "cell_type": "code",
      "source": [
        "# Bush Inaugural Address\n",
        "\n",
        "X_train_tfidf, X_test_tfidf= train_test_split(bush_inaug_tfidf, test_size=0.3, random_state=0)\n",
        "\n",
        "\n",
        "#Reshapes the vectorizer output into something people can read\n",
        "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
        "\n",
        "#number of paragraphs\n",
        "n = X_train_tfidf_csr.shape[0]\n",
        "#A list of dictionaries, one per paragraph\n",
        "tfidf_bypara = [{} for _ in range(0,n)]\n",
        "#List of features\n",
        "terms = vectorizer.get_feature_names()\n",
        "#for each paragraph, lists the feature words and their tf-idf scores\n",
        "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
        "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
        "\n",
        "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
        "print('Original sentence:', X_train[2])\n",
        "print('Tf_idf vector:', tfidf_bypara[2])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence: But the stakes for America are never small .\n",
            "Tf_idf vector: {'small': 3.8134107167600364, 'stakes': 3.8134107167600364, 'america': 2.4271163556401456}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RvnlXtnmkHWX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7aa1f892-97ec-4663-ff66-95754a20fc59"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
        "svd= TruncatedSVD(10)\n",
        "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
        "# Run SVD on the training data, then project the training data.\n",
        "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
        "\n",
        "variance_explained=svd.explained_variance_ratio_\n",
        "total_variance = variance_explained.sum()\n",
        "print(\"Percent variance captured by all components:\",total_variance*100)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent variance captured by all components: 67.46275961215484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2U5yB_rnxWMK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
        "svd= TruncatedSVD(10)\n",
        "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
        "# Run SVD on the training data, then project the training data.\n",
        "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
        "\n",
        "variance_explained=svd.explained_variance_ratio_\n",
        "total_variance = variance_explained.sum()\n",
        "print(\"Percent variance captured by all components:\",total_variance*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1dVjdbxfngN_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "bd98dfa9-a25d-4c29-889a-f043174945ab"
      },
      "cell_type": "code",
      "source": [
        "# Compute document similarity using LSA components\n",
        "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
        "#Only taking the first 10 sentences\n",
        "sim_matrix=pd.DataFrame(similarity,index=X_train).iloc[0:10,0:10]\n",
        "#Making a plot\n",
        "ax = sns.heatmap(sim_matrix,yticklabels=range(10))\n",
        "plt.show()\n",
        "\n",
        "#Generating a key for the plot.\n",
        "print('Key:')\n",
        "for i in range(10):\n",
        "    print(i,sim_matrix.index[i])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAD4CAYAAAA94VfoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3VxJ4gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Key:\n",
            "0 And I thank Vice President Gore for a contest conducted with spirit and ended with grace .\n",
            "1 Never tiring , never yielding , never finishing , we renew that purpose today , to make our country more just and generous , to affirm the dignity of our lives and every life .\n",
            "2 But the stakes for America are never small .\n",
            "3 Today , we affirm a new commitment to live out our nation ' s promise through civility , courage , compassion and character .\n",
            "4 And whatever our views of its cause , we can agree that children at risk are not at fault .\n",
            "5 Together , we will reclaim America ' s schools , before ignorance and apathy claim more young lives .\n",
            "6 America , at its best , matches a commitment to principle with a concern for civility .\n",
            "7 What you do is as important as anything government does .\n",
            "8 America , at its best , is also courageous .\n",
            "9 Americans are generous and strong and decent , not because we believe in ourselves , but because we hold beliefs beyond ourselves .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M-SYHQHHxiPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab36bec2-7c3c-433f-89e1-26bd46ee97b8"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "X_train, X_test = train_test_split(obama_paras, test_size=0.3, random_state=0)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
        "                             min_df=2, # only use words that appear at least twice\n",
        "                             stop_words='english', \n",
        "                             lowercase=True, #convert everything to lower case\n",
        "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
        "                             norm=None, #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
        "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
        "                            )\n",
        "\n",
        "#Applying the vectorizer\n",
        "obama_inaug_tfidf=vectorizer.fit_transform(obama_paras)\n",
        "print(\"Number of features: %d\" % obama_inaug_tfidf.get_shape()[1])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features: 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A2-qkt4_pVSA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f72cb4d0-fc66-4f03-8812-5f61db4584f1"
      },
      "cell_type": "code",
      "source": [
        "# Obama Inaugural Address\n",
        "\n",
        "X_train_tfidf, X_test_tfidf= train_test_split(obama_inaug_tfidf, test_size=0.3, random_state=0)\n",
        "\n",
        "\n",
        "#Reshapes the vectorizer output into something people can read\n",
        "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
        "\n",
        "#number of paragraphs\n",
        "n = X_train_tfidf_csr.shape[0]\n",
        "#A list of dictionaries, one per paragraph\n",
        "tfidf_bypara = [{} for _ in range(0,n)]\n",
        "#List of features\n",
        "terms = vectorizer.get_feature_names()\n",
        "#for each paragraph, lists the feature words and their tf-idf scores\n",
        "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
        "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
        "\n",
        "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
        "print('Original sentence:', X_train[2])\n",
        "print('Tf_idf vector:', tfidf_bypara[2])"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence: Our challenges may be new .\n",
            "Tf_idf vector: {'new': 3.224623551524334, 'challenges': 3.512305623976115}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GSVp8g0OrbA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5331da39-ad47-4700-d19e-48e5e2f98455"
      },
      "cell_type": "code",
      "source": [
        "#Our SVD data reducer.  We are going to reduce the feature space from 1379 to 130.\n",
        "svd= TruncatedSVD(10)\n",
        "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
        "# Run SVD on the training data, then project the training data.\n",
        "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
        "\n",
        "variance_explained=svd.explained_variance_ratio_\n",
        "total_variance = variance_explained.sum()\n",
        "print(\"Percent variance captured by all components:\",total_variance*100)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent variance captured by all components: 86.1705699802513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JoIkY5RSr9GN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "f226e9d0-c31e-4454-ed08-5c40dc9141c1"
      },
      "cell_type": "code",
      "source": [
        "# Compute document similarity using LSA components\n",
        "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
        "#Only taking the first 10 sentences\n",
        "sim_matrix=pd.DataFrame(similarity,index=X_train).iloc[0:10,0:10]\n",
        "#Making a plot\n",
        "ax = sns.heatmap(sim_matrix,yticklabels=range(10))\n",
        "plt.show()\n",
        "\n",
        "#Generating a key for the plot.\n",
        "print('Key:')\n",
        "for i in range(10):\n",
        "    print(i,sim_matrix.index[i])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAD4CAYAAAA94VfoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiI5UhEWEcmRirCISI5UhEVEcvR/97YkXGcaYKMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Key:\n",
            "0 Thank you .\n",
            "1 \" Let it be told to the future world ... that in the depth of winter , when nothing but hope and virtue could survive ... that the city and the country , alarmed at one common danger , came forth to meet ...\n",
            "2 Our challenges may be new .\n",
            "3 So let us mark this day with remembrance , of who we are and how far we have traveled .\n",
            "4 On this day , we come to proclaim an end to the petty grievances and false promises , the recriminations and worn - out dogmas that for far too long have strangled our politics .\n",
            "5 For us , they fought and died , in places like Concord and Gettysburg ; Normandy and Khe Sahn .\n",
            "6 These are the indicators of crisis , subject to data and statistics .\n",
            "7 Now , there are some who question the scale of our ambitions  who suggest that our system cannot tolerate too many big plans .\n",
            "8 Time and again these men and women struggled and sacrificed and worked till their hands were raw so that we might live a better life .\n",
            "9 On this day , we gather because we have chosen hope over fear , unity of purpose over conflict and discord .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cz-xM9GNsDkP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}