{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boost guided example\n",
    "\n",
    "Having walked through gradient boost by hand, now let's try it with SKlearn.  We'll still use the European Social Survey Data, but now with a categorical outcome: Whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "\n",
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner'] - 1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're now working with a binary outcome, we've switched to a classifier.  Now our loss function can't be the residuals.  Our options are \"deviance\", or \"exponential\".  Deviance is used for logistic regression, and we'll try that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04650845608292417\n",
      "Percent Type II errors: 0.17607746863066012\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06257668711656442\n",
      "Percent Type II errors: 0.18527607361963191\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike decision trees, gradient boost solutions are not terribly easy to interpret on the surface.  But they aren't quite a black box.  We can get a measure of how important various features are by counting how many times a feature is used over the course of many decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = clf.feature_importances_\n",
    "\n",
    "# Make importances relative to max importance.\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that age and happiness are the most important features in predicting whether or not someone lives with a partner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### DRILL: Improve this gradient boost model\n",
    "\n",
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement.  Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set.  Strategies you might use include:\n",
    "\n",
    "* Creating new features\n",
    "* Applying more overfitting-prevention strategies like subsampling\n",
    "* More iterations\n",
    "* Trying a different loss function\n",
    "* Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications\n",
    "\n",
    "Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
       "0    CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
       "1    CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
       "2    CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
       "3    CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
       "4    CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
       "\n",
       "   gndr  agea  partner  \n",
       "0   2.0  60.0      1.0  \n",
       "1   2.0  59.0      1.0  \n",
       "2   1.0  24.0      2.0  \n",
       "3   2.0  64.0      1.0  \n",
       "4   2.0  55.0      1.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADW9JREFUeJzt3V2oXWedx/HvbxqrtqKt7aloEuZUDI4iDC3BqRZkMA5YK6YXLXSY0SCB3HS0WkGjN96mIFaFoRAancgUX4iFBluckbYyzIXB9AX7EqWhdppjoz1iWx1FtPifi/OUOaSnzY45++yef74fCHu9PHuvZ5Hwzco6e++kqpAk9fVXs56AJGm6DL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOY2zHoCABdeeGHNz8/PehqStK7ce++9v6qquZONe1mEfn5+nsOHD896GpK0riT5n0nGeetGkpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmntZfDJWkgDmd98xk+M+vufKmRx3rXhFL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnN+142kM96svmMH1uZ7dryil6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLU3EShT/LJJA8neSjJN5K8KsnFSQ4leTTJt5KcPca+cqwfHfvnp3kCkqSXdtLQJ9kIfBzYWlXvAM4CrgVuBG6qqi3A08DO8ZSdwNNV9RbgpjFOkjQjk9662QC8OskG4BzgOPBe4MDYvx+4aixvH+uM/duSZHWmK0k6VScNfVX9HPgC8ARLgX8WuBd4pqqeG8MWgI1jeSNwbDz3uTH+gtWdtiRpUpPcujmfpav0i4E3AecCV6wwtJ5/ykvsW/66u5IcTnJ4cXFx8hlLkk7JJLdu3gf8rKoWq+pPwG3Au4Hzxq0cgE3Ak2N5AdgMMPa/Dvj1iS9aVXuramtVbZ2bmzvN05AkvZhJQv8EcFmSc8a99m3AI8A9wNVjzA7g9rF8cKwz9t9dVS+4opckrY1J7tEfYumHqvcBD47n7AU+A9yQ5ChL9+D3jafsAy4Y228Adk9h3pKkCU30H49U1eeBz5+w+THgnSuM/QNwzelPTZK0GvxkrCQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqbqLQJzkvyYEkP0lyJMm7krw+yfeTPDoezx9jk+QrSY4m+XGSS6d7CpKkl7JhwnFfBr5XVVcnORs4B/gccFdV7UmyG9gNfAa4Atgyfv0dcPN4lLQOzO++Y9ZT0Co76RV9ktcC7wH2AVTVH6vqGWA7sH8M2w9cNZa3A1+vJT8EzkvyxlWfuSRpIpPcunkzsAh8Lcn9SW5Jci7whqo6DjAeLxrjNwLHlj1/YWyTJM3AJKHfAFwK3FxVlwC/Y+k2zYvJCtvqBYOSXUkOJzm8uLg40WQlSaduktAvAAtVdWisH2Ap/L98/pbMeHxq2fjNy56/CXjyxBetqr1VtbWqts7Nzf2l85ckncRJQ19VvwCOJXnr2LQNeAQ4COwY23YAt4/lg8BHxrtvLgOeff4WjyRp7U36rpuPAbeOd9w8BnyUpb8kvp1kJ/AEcM0YeyfwAeAo8PsxVpI0IxOFvqoeALausGvbCmMLuO405yVJWiV+MlaSmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJam5iUOf5Kwk9yf57li/OMmhJI8m+VaSs8f2V471o2P//HSmLkmaxKlc0V8PHFm2fiNwU1VtAZ4Gdo7tO4Gnq+otwE1jnCRpRiYKfZJNwJXALWM9wHuBA2PIfuCqsbx9rDP2bxvjJUkzMOkV/ZeATwN/HusXAM9U1XNjfQHYOJY3AscAxv5nx3hJ0gycNPRJPgg8VVX3Lt+8wtCaYN/y192V5HCSw4uLixNNVpJ06ia5or8c+FCSx4FvsnTL5kvAeUk2jDGbgCfH8gKwGWDsfx3w6xNftKr2VtXWqto6Nzd3WichSXpxJw19VX22qjZV1TxwLXB3Vf0TcA9w9Ri2A7h9LB8c64z9d1fVC67oJUlr43TeR/8Z4IYkR1m6B79vbN8HXDC23wDsPr0pSpJOx4aTD/l/VfUD4Adj+THgnSuM+QNwzSrMTZK0CvxkrCQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtScxtmPQHp5Wx+9x0zO/bje66c2bHVi1f0ktScoZek5gy9JDVn6CWpOX8YK71MzfIHwerFK3pJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnMnDX2SzUnuSXIkycNJrh/bX5/k+0keHY/nj+1J8pUkR5P8OMml0z4JSdKLm+SK/jngU1X1NuAy4Lokbwd2A3dV1RbgrrEOcAWwZfzaBdy86rOWJE3spKGvquNVdd9Y/i1wBNgIbAf2j2H7gavG8nbg67Xkh8B5Sd646jOXJE3klO7RJ5kHLgEOAW+oquOw9JcBcNEYthE4tuxpC2Pbia+1K8nhJIcXFxdPfeaSpIlMHPokrwG+A3yiqn7zUkNX2FYv2FC1t6q2VtXWubm5SachSTpFE4U+yStYivytVXXb2PzL52/JjMenxvYFYPOyp28Cnlyd6UqSTtUk77oJsA84UlVfXLbrILBjLO8Abl+2/SPj3TeXAc8+f4tHkrT2Jvkfpi4HPgw8mOSBse1zwB7g20l2Ak8A14x9dwIfAI4Cvwc+uqozliSdkpOGvqr+m5XvuwNsW2F8Aded5rwkSavET8ZKUnOGXpKaM/SS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc4Zekpoz9JLUnKGXpOYMvSQ1Z+glqTlDL0nNGXpJas7QS1Jzhl6SmjP0ktScoZek5gy9JDVn6CWpuQ2znoA0ifndd8x6CtK6Zeh1SgyutP5460aSmjP0ktScoZek5gy9JDVn6CWpOUMvSc0ZeklqztBLUnN+YGod8kNLkk6FV/SS1Jyhl6TmDL0kNTeVe/RJ3g98GTgLuKWq9kzjODDb+9WP77lyZseWpEmteuiTnAX8K/APwALwoyQHq+qR1T7WrPlDUUnrwTRu3bwTOFpVj1XVH4FvAtuncBxJ0gSmEfqNwLFl6wtjmyRpBqZxjz4rbKsXDEp2AbvG6v8m+elfeLwLgV/9hc9drzznM4PnfAbIjad1zn89yaBphH4B2LxsfRPw5ImDqmovsPd0D5bkcFVtPd3XWU885zOD53xmWItznsatmx8BW5JcnORs4Frg4BSOI0mawKpf0VfVc0n+BfgPlt5e+dWqeni1jyNJmsxU3kdfVXcCd07jtVdw2rd/1iHP+czgOZ8Zpn7OqXrBz0klSY34FQiS1Ny6Dn2S9yf5aZKjSXbPej7TlmRzknuSHEnycJLrZz2ntZDkrCT3J/nurOeyFpKcl+RAkp+M3+t3zXpO05bkk+PP9ENJvpHkVbOe02pL8tUkTyV5aNm21yf5fpJHx+P50zj2ug39sq9auAJ4O/CPSd4+21lN3XPAp6rqbcBlwHVnwDkDXA8cmfUk1tCXge9V1d8Af0vzc0+yEfg4sLWq3sHSmziune2spuLfgPefsG03cFdVbQHuGuurbt2GnjPwqxaq6nhV3TeWf8tSAFp/6jjJJuBK4JZZz2UtJHkt8B5gH0BV/bGqnpntrNbEBuDVSTYA57DCZ2/Wu6r6L+DXJ2zeDuwfy/uBq6Zx7PUc+jP6qxaSzAOXAIdmO5Op+xLwaeDPs57IGnkzsAh8bdyuuiXJubOe1DRV1c+BLwBPAMeBZ6vqP2c7qzXzhqo6DksXcsBF0zjIeg79RF+10FGS1wDfAT5RVb+Z9XymJckHgaeq6t5Zz2UNbQAuBW6uqkuA3zGlf86/XIz70tuBi4E3Aecm+efZzqqX9Rz6ib5qoZskr2Ap8rdW1W2zns+UXQ58KMnjLN2ae2+Sf5/tlKZuAVioquf/pXaApfB39j7gZ1W1WFV/Am4D3j3jOa2VXyZ5I8B4fGoaB1nPoT/jvmohSVi6d3ukqr446/lMW1V9tqo2VdU8S7+/d1dV6yu9qvoFcCzJW8embUC7/8vhBE8AlyU5Z/wZ30bzH0AvcxDYMZZ3ALdP4yBT+WTsWjhDv2rhcuDDwINJHhjbPjc+iaw+PgbcOi5gHgM+OuP5TFVVHUpyALiPpXeW3U/DT8gm+Qbw98CFSRaAzwN7gG8n2cnSX3jXTOXYfjJWknpbz7duJEkTMPSS1Jyhl6TmDL0kNWfoJak5Qy9JzRl6SWrO0EtSc/8HOHwX7RcpaVkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing some features\n",
    "test = df.loc[df['partner'] == 2]\n",
    "plt.hist(test.happy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['younger_happier'] = (df['agea'] > 35) & (df['happy'] < 5)\n",
    "df['younger_happier'] = pd.get_dummies(df['younger_happier'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('younger_happier', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y2 = df['partner'] - 1\n",
    "X2 = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]\n",
    "\n",
    "# Make the categorical variable 'country' into dummies.\n",
    "X2 = pd.concat([X2, pd.get_dummies(df['cntry'])], axis=1)\n",
    "\n",
    "# Create training and test sets.\n",
    "offset = int(X2.shape[0] * 0.9)\n",
    "\n",
    "# Put 90% of the data in the training set.\n",
    "X2_train, y2_train = X2[:offset], y2[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X2_test, y2_test = X2[offset:], y2[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.006955810147299509\n",
      "Percent Type II errors: 0.055100927441352976\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.1263803680981595\n",
      "Percent Type II errors: 0.16932515337423312\n"
     ]
    }
   ],
   "source": [
    "# We'll make 500 iterations, use 2-deep trees, and set our loss function.\n",
    "params = {'n_estimators': 1500,\n",
    "          'max_depth': 4,\n",
    "          'loss': 'deviance'}\n",
    "\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X2_train, y2_train)\n",
    "\n",
    "predict_train = clf.predict(X2_train)\n",
    "predict_test = clf.predict(X2_test)\n",
    "\n",
    "# Accuracy tables.\n",
    "table_train = pd.crosstab(y2_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y2_test, predict_test, margins=True)\n",
    "\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n",
    "\n",
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>CH</th>\n",
       "      <th>CZ</th>\n",
       "      <th>DE</th>\n",
       "      <th>ES</th>\n",
       "      <th>NO</th>\n",
       "      <th>SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  gndr  agea  \\\n",
       "0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   2.0  60.0   \n",
       "1     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   2.0  59.0   \n",
       "2     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   1.0  24.0   \n",
       "3     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   2.0  64.0   \n",
       "4     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   2.0  55.0   \n",
       "\n",
       "   CH  CZ  DE  ES  NO  SE  \n",
       "0   1   0   0   0   0   0  \n",
       "1   1   0   0   0   0   0  \n",
       "2   1   0   0   0   0   0  \n",
       "3   1   0   0   0   0   0  \n",
       "4   1   0   0   0   0   0  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of estimators and the depth of the trees created a bit more overfitting of the training data but still had a slight affect on the test data - decreasing the % of Type II errors in both.\n",
    "\n",
    "Creating some new features that focused on the 2 most important features had little affects on the Type I-Type II outcomes."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "59px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
